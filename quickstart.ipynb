{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "- https://python.langchain.com/docs/get_started/quickstart\n",
    "- https://python.langchain.com/docs/integrations/llms/azure_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nLangsmith is a language model that can assist with testing in several ways:\\n\\n1. Automated Testing: Langsmith can be used to generate automated tests for software applications. It can analyze the application's code and generate test cases based on the syntax and semantics of the code. This can help save time and effort in writing manual tests, and also improve testing coverage and accuracy.\\n2. Code Coverage Analysis: Langsmith can analyze the test cases generated by it or any other test suite, and provide information on the code coverage of the tests. It can identify areas of the code that are not being tested enough, or areas where tests are not effective in detecting errors.\\n3. Test Data Generation: Langsmith can be used to generate test data that is relevant to a specific application or feature. For example, it can generate test data for a web application based on user interactions, or generate test cases for a mobile app based on real-world usage scenarios.\\n4. Regression Testing: Langsmith can be used to identify changes in the codebase over time and generate regression tests that cover the modified areas of the code. This can help ensure that changes made to the code do not introduce new bugs or break existing functionality.\\n5. Code Review: Langsmith can be used to review code changes and identify potential issues before they become problems. It can analyze the changed code and suggest improvements, or identify areas where the code may be vulnerable to errors or security threats.\\n6. Test Prioritization: Langsmith can be used to prioritize tests based on risk and impact. It can help identify the most critical tests to run first, based on factors such as the severity of the potential issues, the likelihood of failure, and the impact on the overall system.\\n7. Test Automation Framework Development: Langsmith can be used to develop and maintain test automation frameworks for various applications. It can generate test cases and test scripts, and help implement test automation solutions that are efficient and effective.\\n8. Defect Prediction: Langsmith can be used to predict potential defects in the code based on historical data and trends. It can identify areas of the code that are likely to fail or have high maintenance costs, and suggest improvements to reduce the likelihood of defects or improve overall code quality.\\n9. Code Quality Analysis: Langsmith can be used to analyze the quality of the codebase based on various metrics such as code complexity, cyclomatic complexity, cohesion, and coupling. It can identify areas where the code may be difficult to maintain or extend, and suggest improvements to improve code quality.\\n10. Testing Strategy Development: Langsmith can be used to develop testing strategies for complex systems or applications. It can help identify the most critical test cases and scenarios, and prioritize tests based on risk and impact.\\n\\nOverall, Langsmith can help automate and improve the testing process, reduce the time and effort required for manual testing, and provide more efficient and effective testing solutions.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAh, an excellent question! As a world-class technical documentation writer, I must say that Langsmith is a versatile tool that can assist with testing in several ways. Here are some of the ways Langsmith can help:\\n\\n1. Automated Testing: Langsmith's AI-powered engine can automatically generate test cases based on your technical documentation. This can save you time and effort while ensuring comprehensive testing. By using Langsmith, you can automate repetitive tasks such as data entry, regression testing, and exploratory testing.\\n2. Test Data Generation: Langsmith's natural language processing (NLP) capabilities allow it to generate test data that mimics real-world scenarios. This can help identify potential issues early on in the development cycle, ensuring that your product is thoroughly tested before release.\\n3. Test Case Prioritization: Langsmith's AI-powered engine can prioritize test cases based on risk and complexity, ensuring that critical tests are executed first. This can help you identify and fix issues early on in the development cycle, reducing the likelihood of bugs and errors making it to production.\\n4. Testing for Complexity: Langsmith's ability to understand complex systems and dependencies means it can generate test cases that cover a wide range of scenarios. By using Langsmith, you can ensure that your product is thoroughly tested in various environments and scenarios, reducing the likelihood of unexpected failures or bugs.\\n5. Collaboration and Knowledge Sharing: As a world-class technical documentation writer, I understand the importance of collaboration and knowledge sharing within teams. Langsmith's platform allows for seamless collaboration between team members, ensuring that everyone is on the same page when it comes to testing. By using Langsmith, you can facilitate better communication and coordination among team members, leading to higher-quality testing and a more robust product.\\n6. Cost Savings: Finally, Langsmith can help reduce costs associated with manual testing by automating repetitive tasks. By using Langsmith's AI-powered engine, you can save time and resources while ensuring comprehensive testing. This can lead to significant cost savings over time, allowing you to invest more in product development and innovation.\\n\\nIn summary, Langsmith is a powerful tool that can assist with testing in various ways, from automated testing to test data generation, prioritization, and collaboration. By leveraging Langsmith's AI-powered engine, you can ensure comprehensive testing while reducing costs and improving team coordination and communication.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAs a world-class technical documentation writer, I must say that Langsmith is an incredible tool for testing purposes! Here are some ways in which Langsmith can help with testing:\\n\\n1. Automated Content Creation: With Langsmith, you can create automated content based on your existing documentation, such as API documentation, user manuals, and more. This can save time and effort during the testing process by reducing the amount of manual work involved in creating test cases.\\n2. Smart Content Analysis: Langsmith's AI-powered content analysis tools can help you identify potential issues with your documentation before they become critical problems. By analyzing your content for consistency, completeness, and accuracy, Langsmith can help you catch mistakes that might otherwise go unnoticed during the testing process.\\n3. Intelligent Testing: With Langsmith's intelligent testing capabilities, you can create more accurate and comprehensive test cases by analyzing your content and identifying areas that require additional testing. This can help you ensure that your documentation is thorough and reliable, which is essential for successful testing.\\n4. Collaboration and Feedback: Langsmith's collaboration features allow you to work with your team more efficiently during the testing process. You can share test cases, provide feedback, and track progress in real-time, ensuring that everyone is on the same page and working towards the same goal.\\n5. Customization: Langsmith allows you to customize your testing process to fit your specific needs. You can create custom test cases, integrate with other tools and systems, and tailor the platform to suit your organization's unique workflows and processes. This flexibility ensures that you can test your documentation effectively and efficiently, without sacrificing quality or accuracy.\\n\\nIn conclusion, Langsmith is an incredible tool for testing technical documentation. With its automated content creation, smart content analysis, intelligent testing capabilities, collaboration features, and customization options, Langsmith can help you streamline the testing process, reduce errors, and ensure that your documentation is accurate and reliable.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBased on the provided context, langsmith can help with testing by allowing users to visualize their test results. This means that langsmith can provide a visual representation of the test results, making it easier for users to understand and analyze the data. This can be particularly useful for complex tests or large amounts of data, as it allows users to quickly identify trends or patterns in the results.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"how can langsmith help with testing?\",\n",
    "    \"context\": [Document(page_content=\"langsmith can let you visualize test results\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrival_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Based on the provided context, LangSmith can help with testing in several ways:\n",
      "\n",
      "1. Prototyping: LangSmith provides a platform for rapid iteration and experimentation, allowing developers to test out different prompts and models quickly.\n",
      "2. Debugging: When developing new LLM applications, LangSmith tracing is enabled by default, providing clear visibility and debugging information at each step of an LLM sequence. This helps identify and root-cause issues when things go wrong.\n",
      "3. Initial Test Set: LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications. These test cases can be uploaded in bulk, created on the fly, or exported from application traces.\n",
      "4. Comparison View: LangSmith provides a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of an application. This helps identify whether or not a variant is performing better than the initial test cases.\n",
      "5. Beta Testing: LangSmith enables users to collect more data on how their LLM applications are performing in real-world scenarios. This phase involves developing an understanding for the types of inputs the app is performing well or poorly on and how exactly it’s breaking down in those cases.\n",
      "6. Annotating Traces: LangSmith also supports sending runs to annotation queues, which allow annotators to closely inspect interesting traces and annotate them with respect to different criteria. This helps catch regressions across important evaluation criteria.\n",
      "7. Adding Runs to a Dataset: As the application progresses through the beta testing phase, users can add runs as examples to datasets, expanding their test coverage on real-world scenarios. This is a key benefit in having both logging and evaluation/testing systems in the same platform.\n",
      "8. Monitoring and A/B Testing: LangSmith provides monitoring charts that allow users to track key metrics over time. Users can view metrics for a given period and drill down into a specific data point to get a trace table for that time period, which is helpful for debugging production issues. Additionally, LangSmith allows for tag and metadata grouping, which enables users to mark different versions of their applications with different identifiers and view how they are performing side-by-side within each chart. This helps with A/B testing changes in prompt, model, or retrieval strategy.\n"
     ]
    }
   ],
   "source": [
    "response = retrival_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"user\", \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\")\n",
    "])\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Skip to main content🦜️🛠️ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyUser GuideOn this pageLangSmith User GuideLangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.Prototyping\\u200bPrototyping LLM applications often involves quick experimentation between prompts, model types, retrieval strategy and other parameters.\\nThe ability to rapidly understand how the model is performing — and debug where it is failing — is incredibly important for this phase.Debugging\\u200bWhen developing new LLM applications, we suggest having LangSmith tracing enabled by default.\\nOftentimes, it isn’t necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), it’s extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.\\nWe provide native rendering of chat messages, functions, and retrieve documents.Initial Test Set\\u200bWhile many developers still ship an initial version of their application based on “vibe checks”, we’ve seen an increasing number of engineering teams start to adopt a more test driven approach. LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.\\nThese test cases can be uploaded in bulk, created on the fly, or exported from application traces. LangSmith also makes it easy to run custom evaluations (both LLM and heuristic based) to score test results.Comparison View\\u200bWhen prototyping different versions of your applications and making changes, it’s important to see whether or not you’ve regressed with respect to your initial test cases.\\nOftentimes, changes in the prompt, retrieval strategy, or model choice can have huge implications in responses produced by your application.\\nIn order to get a sense for which variant is performing better, it’s useful to be able to view results for different configurations on the same datapoints side-by-side. We’ve invested heavily in a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of your application.Playground\\u200bLangSmith provides a playground environment for rapid iteration and experimentation.\\nThis allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}),\n",
       " Document(page_content=\"This allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.\\nEvery playground run is logged in the system and can be used to create test cases or compare with other runs.Beta Testing\\u200bBeta testing allows developers to collect more data on how their LLM applications are performing in real-world scenarios. In this phase, it’s important to develop an understanding for the types of inputs the app is performing well or poorly on and how exactly it’s breaking down in those cases. Both feedback collection and run annotation are critical for this workflow. This will help in curation of test cases that can help track regressions/improvements and development of automatic evaluations.Collecting Feedback\\u200bWhen launching your application to an initial set of users, it’s important to gather human feedback on the responses it’s producing. This helps draw attention to the most interesting runs and highlight edge cases that are causing problematic responses. LangSmith allows you to attach feedback scores to logged traces (oftentimes, this is hooked up to a feedback button in your app), then filter on traces that have a specific feedback tag and score. A common workflow is to filter on traces that receive a poor user feedback score, then drill down into problematic points using the detailed trace view.Annotating Traces\\u200bLangSmith also supports sending runs to annotation queues, which allow annotators to closely inspect interesting traces and annotate them with respect to different criteria. Annotators can be PMs, engineers, or even subject matter experts. This allows users to catch regressions across important evaluation criteria.Adding Runs to a Dataset\\u200bAs your application progresses through the beta testing phase, it's essential to continue collecting data to refine and improve its performance. LangSmith enables you to add runs as examples to datasets (from both the project page and within an annotation queue), expanding your test coverage on real-world scenarios. This is a key benefit in having your logging system and your evaluation/testing system in the same platform.Production\\u200bClosely inspecting key data points, growing benchmarking datasets, annotating traces, and drilling down into important data in trace view are workflows you’ll also want to do once your app hits production. However, especially at the production stage, it’s crucial to get a high-level overview of application performance with respect to latency, cost, and feedback scores. This ensures that it's delivering desirable results at scale.Monitoring and A/B Testing\\u200bLangSmith provides monitoring charts that allow you to track key metrics over time. You can expand to view metrics for a given period and drill down into a specific data point to get a trace table for that time period — this is especially handy for debugging production issues.LangSmith also allows for tag and metadata grouping, which allows users to mark different versions of their applications with different identifiers and view how they are performing side-by-side within each chart. This is helpful for A/B testing changes in prompt, model, or retrieval strategy.Help us out by providing feedback on this documentation page:PreviousLangSmithNextSetupPrototypingBeta TestingProductionCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright © 2024 LangChain, Inc.\", metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}),\n",
       " Document(page_content='LangSmith User Guide | 🦜️🛠️ LangSmith', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retriever_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retrival_chain = create_retrieval_chain(retriever_chain, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Can LangSmith help test my LLM applications?'),\n",
       "  AIMessage(content='Yes!')],\n",
       " 'input': 'Tell me how',\n",
       " 'context': [Document(page_content='Skip to main content🦜️🛠️ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyUser GuideOn this pageLangSmith User GuideLangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.Prototyping\\u200bPrototyping LLM applications often involves quick experimentation between prompts, model types, retrieval strategy and other parameters.\\nThe ability to rapidly understand how the model is performing — and debug where it is failing — is incredibly important for this phase.Debugging\\u200bWhen developing new LLM applications, we suggest having LangSmith tracing enabled by default.\\nOftentimes, it isn’t necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), it’s extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.\\nWe provide native rendering of chat messages, functions, and retrieve documents.Initial Test Set\\u200bWhile many developers still ship an initial version of their application based on “vibe checks”, we’ve seen an increasing number of engineering teams start to adopt a more test driven approach. LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.\\nThese test cases can be uploaded in bulk, created on the fly, or exported from application traces. LangSmith also makes it easy to run custom evaluations (both LLM and heuristic based) to score test results.Comparison View\\u200bWhen prototyping different versions of your applications and making changes, it’s important to see whether or not you’ve regressed with respect to your initial test cases.\\nOftentimes, changes in the prompt, retrieval strategy, or model choice can have huge implications in responses produced by your application.\\nIn order to get a sense for which variant is performing better, it’s useful to be able to view results for different configurations on the same datapoints side-by-side. We’ve invested heavily in a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of your application.Playground\\u200bLangSmith provides a playground environment for rapid iteration and experimentation.\\nThis allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}),\n",
       "  Document(page_content='LangSmith User Guide | 🦜️🛠️ LangSmith', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}),\n",
       "  Document(page_content=\"This allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.\\nEvery playground run is logged in the system and can be used to create test cases or compare with other runs.Beta Testing\\u200bBeta testing allows developers to collect more data on how their LLM applications are performing in real-world scenarios. In this phase, it’s important to develop an understanding for the types of inputs the app is performing well or poorly on and how exactly it’s breaking down in those cases. Both feedback collection and run annotation are critical for this workflow. This will help in curation of test cases that can help track regressions/improvements and development of automatic evaluations.Collecting Feedback\\u200bWhen launching your application to an initial set of users, it’s important to gather human feedback on the responses it’s producing. This helps draw attention to the most interesting runs and highlight edge cases that are causing problematic responses. LangSmith allows you to attach feedback scores to logged traces (oftentimes, this is hooked up to a feedback button in your app), then filter on traces that have a specific feedback tag and score. A common workflow is to filter on traces that receive a poor user feedback score, then drill down into problematic points using the detailed trace view.Annotating Traces\\u200bLangSmith also supports sending runs to annotation queues, which allow annotators to closely inspect interesting traces and annotate them with respect to different criteria. Annotators can be PMs, engineers, or even subject matter experts. This allows users to catch regressions across important evaluation criteria.Adding Runs to a Dataset\\u200bAs your application progresses through the beta testing phase, it's essential to continue collecting data to refine and improve its performance. LangSmith enables you to add runs as examples to datasets (from both the project page and within an annotation queue), expanding your test coverage on real-world scenarios. This is a key benefit in having your logging system and your evaluation/testing system in the same platform.Production\\u200bClosely inspecting key data points, growing benchmarking datasets, annotating traces, and drilling down into important data in trace view are workflows you’ll also want to do once your app hits production. However, especially at the production stage, it’s crucial to get a high-level overview of application performance with respect to latency, cost, and feedback scores. This ensures that it's delivering desirable results at scale.Monitoring and A/B Testing\\u200bLangSmith provides monitoring charts that allow you to track key metrics over time. You can expand to view metrics for a given period and drill down into a specific data point to get a trace table for that time period — this is especially handy for debugging production issues.LangSmith also allows for tag and metadata grouping, which allows users to mark different versions of their applications with different identifiers and view how they are performing side-by-side within each chart. This is helpful for A/B testing changes in prompt, model, or retrieval strategy.Help us out by providing feedback on this documentation page:PreviousLangSmithNextSetupPrototypingBeta TestingProductionCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright © 2024 LangChain, Inc.\", metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'})],\n",
       " 'answer': 'Of course, I\\'d be happy to help you understand how LangSmith can support testing your LLM applications. Here are some key features and capabilities of LangSmith that can assist in the testing process:\\n\\n1. Prototyping: LangSmith provides a playground environment for rapid iteration and experimentation. You can test out different prompts and models, and open the playground from any prompt or model run in your trace. Every playground run is logged in the system and can be used to create test cases or compare with other runs.\\n2. Debugging: When developing new LLM applications, LangSmith tracing is enabled by default. You can debug by looking through the application traces to identify and root-cause issues. We provide native rendering of chat messages, functions, and retrieve documents.\\n3. Initial Test Set: While many developers still ship an initial version of their application based on \"vibe checks,\" LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications. These test cases can be uploaded in bulk, created on the fly, or exported from application traces.\\n4. Comparison View: When prototyping different versions of your applications and making changes, it\\'s important to see whether or not you\\'ve regressed with respect to your initial test cases. LangSmith provides a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of your application.\\n5. Beta Testing: Beta testing allows developers to collect more data on how their LLM applications are performing in real-world scenarios. In this phase, it\\'s important to develop an understanding for the types of inputs the app is performing well or poorly on and how exactly it\\'s breaking down in those cases. Both feedback collection and run annotation are critical for this workflow.\\n6. Annotating Traces: LangSmith also supports sending runs to annotation queues, which allow annotators to closely inspect interesting traces and annotate them with respect to different criteria. This allows users to catch regressions across important evaluation criteria.\\n7. Adding Runs to a Dataset: As your application progresses through the beta testing phase, it\\'s essential to continue collecting data to refine and improve its performance. LangSmith enables you to add runs as examples to datasets (from both the project page and within an annotation queue), expanding your test coverage on real-world scenarios.\\n8. Production: Closely inspecting key data points, growing benchmarking datasets, annotating traces, and drilling down into important data in trace view are workflows you\\'ll also want to do once your app hits production. However, especially at the production stage, it\\'s crucial to get a high-level overview of application performance with respect to latency, cost, and feedback scores.\\n9. Monitoring and A/B Testing: LangSmith provides monitoring charts that allow you to track key metrics over time. You can expand to view metrics for a given period and drill down into a specific data point to get a trace table for that time period — this is especially handy for A/B testing changes in prompt, model, or retrieval strategy.\\n\\nIn summary, LangSmith offers various features and capabilities to support testing your LLM applications, including prototyping, debugging, initial test sets, comparison views, beta testing, annotating traces, adding runs to a dataset, production monitoring, and A/B testing.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retrival_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool, search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "llm = AzureChatOpenAI(azure_deployment=\"gpt-35-turbo\", temperature=0)\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executer = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mLangSmith can help with testing in several ways:\n",
      "\n",
      "1. Test Case Generation: LangSmith can generate test cases automatically based on the specifications or requirements of the software being tested. It uses advanced techniques such as symbolic execution and constraint solving to generate test inputs that cover different paths and conditions in the code.\n",
      "\n",
      "2. Test Oracles: LangSmith can help in defining test oracles, which are the expected outputs or behaviors of the software under test. It can analyze the code and specifications to automatically generate assertions or checks that can be used as test oracles.\n",
      "\n",
      "3. Test Coverage Analysis: LangSmith can analyze the code and track the coverage of the test cases. It can provide information on which parts of the code are covered by the tests and which parts are not. This helps in identifying areas that need more testing and improving the overall test coverage.\n",
      "\n",
      "4. Test Prioritization: LangSmith can prioritize the test cases based on their importance or likelihood of finding bugs. It can analyze the code and identify critical paths or areas that are more prone to errors. This helps in focusing the testing efforts on the most important parts of the software.\n",
      "\n",
      "5. Test Execution: LangSmith can execute the generated test cases and provide feedback on the results. It can detect failures or errors in the code and provide detailed information on the root cause of the failure. This helps in debugging and fixing the issues.\n",
      "\n",
      "Overall, LangSmith can automate and optimize various aspects of the testing process, making it more efficient and effective.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how can langsmith help with testing?',\n",
       " 'output': 'LangSmith can help with testing in several ways:\\n\\n1. Test Case Generation: LangSmith can generate test cases automatically based on the specifications or requirements of the software being tested. It uses advanced techniques such as symbolic execution and constraint solving to generate test inputs that cover different paths and conditions in the code.\\n\\n2. Test Oracles: LangSmith can help in defining test oracles, which are the expected outputs or behaviors of the software under test. It can analyze the code and specifications to automatically generate assertions or checks that can be used as test oracles.\\n\\n3. Test Coverage Analysis: LangSmith can analyze the code and track the coverage of the test cases. It can provide information on which parts of the code are covered by the tests and which parts are not. This helps in identifying areas that need more testing and improving the overall test coverage.\\n\\n4. Test Prioritization: LangSmith can prioritize the test cases based on their importance or likelihood of finding bugs. It can analyze the code and identify critical paths or areas that are more prone to errors. This helps in focusing the testing efforts on the most important parts of the software.\\n\\n5. Test Execution: LangSmith can execute the generated test cases and provide feedback on the results. It can detect failures or errors in the code and provide detailed information on the root cause of the failure. This helps in debugging and fixing the issues.\\n\\nOverall, LangSmith can automate and optimize various aspects of the testing process, making it more efficient and effective.'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'https://weather.com/weather/tenday/l/San Francisco CA USCA0987:1:US', 'content': \"Comfy & Cozy\\nThat's Not What Was Expected\\nOutside\\n'No-Name Storms' In Florida\\nGifts From On High\\nWhat To Do For Wheezing\\nSurviving The Season\\nStay Safe\\nAir Quality Index\\nAir quality is considered satisfactory, and air pollution poses little or no risk.\\n Health & Activities\\nSeasonal Allergies and Pollen Count Forecast\\nNo pollen detected in your area\\nCold & Flu Forecast\\nFlu risk is low in your area\\nWe recognize our responsibility to use data and technology for good. recents\\nSpecialty Forecasts\\n10 Day Weather-San Francisco, CA\\nToday\\nMon 18 | Day\\nConsiderable cloudiness. Tue 19\\nTue 19 | Day\\nLight rain early...then remaining cloudy with showers in the afternoon. Wed 27\\nWed 27 | Day\\nOvercast with rain showers at times.\"}, {'url': 'https://forecast.weather.gov/zipcity.php?inputstring=San+Francisco,CA', 'content': '50°F 10°C More Information: Local Forecast Office More Local Wx 3 Day History Mobile Weather Hourly Weather Forecast Extended Forecast for San Francisco CA Click here for hazard details and duration High Surf Advisory Wind Advisory NOW: Multiple hazards in effect Click HERE for Details Overnight Showers and Breezy Low: 44 °F Saturday Showers'}, {'url': 'https://www.accuweather.com/en/us/san-francisco/94103/weather-forecast/347629', 'content': 'Get the current and future weather conditions for San Francisco, CA, including temperature, precipitation, wind, air quality and more. See the hourly and 10-day outlook, radar maps, alerts and allergy information.'}, {'url': 'https://www.accuweather.com/en/us/san-francisco/94103/current-weather/347629', 'content': 'Get the latest weather conditions and outlook for San Francisco, CA, including temperature, humidity, wind, pressure, and cloud cover. See alerts, sunrise and sunset times, and historical data for the city.'}, {'url': 'https://www.wunderground.com/forecast/us/ca/san-francisco', 'content': 'Get the latest weather information for San Francisco, CA, including temperature, precipitation, wind speed, and humidity. See the hourly and 10-day forecast for the South of Market station and other nearby weather stations.'}]\u001b[0m\u001b[32;1m\u001b[1;3mThe weather in San Francisco is currently 50°F (10°C) with showers and breezy conditions. You can find more information about the weather in San Francisco on the following websites:\n",
      "\n",
      "- [Weather.com](https://weather.com/weather/tenday/l/San%20Francisco%20CA%20USCA0987:1:US)\n",
      "- [National Weather Service](https://forecast.weather.gov/zipcity.php?inputstring=San+Francisco,CA)\n",
      "- [AccuWeather](https://www.accuweather.com/en/us/san-francisco/94103/weather-forecast/347629)\n",
      "- [Weather Underground](https://www.wunderground.com/forecast/us/ca/san-francisco)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the weather in SF?',\n",
       " 'output': 'The weather in San Francisco is currently 50°F (10°C) with showers and breezy conditions. You can find more information about the weather in San Francisco on the following websites:\\n\\n- [Weather.com](https://weather.com/weather/tenday/l/San%20Francisco%20CA%20USCA0987:1:US)\\n- [National Weather Service](https://forecast.weather.gov/zipcity.php?inputstring=San+Francisco,CA)\\n- [AccuWeather](https://www.accuweather.com/en/us/san-francisco/94103/weather-forecast/347629)\\n- [Weather Underground](https://www.wunderground.com/forecast/us/ca/san-francisco)'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.invoke({\"input\": \"what is the weather in SF?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mLangSmith can help test your LLM applications in the following ways:\n",
      "\n",
      "1. Personal Statement Review: LangSmith can provide feedback and suggestions on your personal statement to ensure it effectively communicates your motivations, experiences, and goals. This includes checking for clarity, coherence, and overall impact.\n",
      "\n",
      "2. Resume/CV Review: LangSmith can review your resume or CV to ensure it is well-structured, highlights your relevant experiences and achievements, and effectively presents your qualifications.\n",
      "\n",
      "3. Recommendation Letter Guidance: LangSmith can provide guidance on selecting appropriate recommenders and offer suggestions on what information to include in your recommendation letter requests.\n",
      "\n",
      "4. Application Strategy: LangSmith can help you develop a comprehensive application strategy, including selecting the right law schools, organizing your application materials, and managing deadlines.\n",
      "\n",
      "5. Interview Preparation: LangSmith can provide mock interviews and offer tips and guidance on how to effectively prepare for your LLM program interviews.\n",
      "\n",
      "6. Research on Law Schools: LangSmith can assist in researching and gathering information about different law schools, including their programs, faculty, and areas of specialization.\n",
      "\n",
      "Please note that while LangSmith can provide valuable guidance and support, it is important to consult with your academic advisors and mentors for personalized advice and feedback on your LLM applications.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Can LangSmith help test my LLM applications?'),\n",
       "  AIMessage(content='Yes!')],\n",
       " 'input': 'Tell me how',\n",
       " 'output': 'LangSmith can help test your LLM applications in the following ways:\\n\\n1. Personal Statement Review: LangSmith can provide feedback and suggestions on your personal statement to ensure it effectively communicates your motivations, experiences, and goals. This includes checking for clarity, coherence, and overall impact.\\n\\n2. Resume/CV Review: LangSmith can review your resume or CV to ensure it is well-structured, highlights your relevant experiences and achievements, and effectively presents your qualifications.\\n\\n3. Recommendation Letter Guidance: LangSmith can provide guidance on selecting appropriate recommenders and offer suggestions on what information to include in your recommendation letter requests.\\n\\n4. Application Strategy: LangSmith can help you develop a comprehensive application strategy, including selecting the right law schools, organizing your application materials, and managing deadlines.\\n\\n5. Interview Preparation: LangSmith can provide mock interviews and offer tips and guidance on how to effectively prepare for your LLM program interviews.\\n\\n6. Research on Law Schools: LangSmith can assist in researching and gathering information about different law schools, including their programs, faculty, and areas of specialization.\\n\\nPlease note that while LangSmith can provide valuable guidance and support, it is important to consult with your academic advisors and mentors for personalized advice and feedback on your LLM applications.'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "agent_executer.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
